{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FA_pretrainedmodels.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v1Akj-I6hKa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#################################### densnet model###############################################3\n",
        "import os\n",
        "from glob import glob\n",
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import layers\n",
        "from keras import Model\n",
        "from keras.applications.densenet import DenseNet201,DenseNet121\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os, shutil\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import glob\n",
        "import numpy as np\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from mpl_toolkits import mplot3d\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten, Reshape, Activation,SimpleRNN,GRU, LSTM\n",
        "from keras.layers.convolutional import Conv2D,Conv3D, Conv2DTranspose, Conv3DTranspose\n",
        "from keras.layers.convolutional import MaxPooling2D,MaxPooling3D, UpSampling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, SimpleRNN, LSTM, GRU, Dropout, Activation, Bidirectional, Conv2D, MaxPooling2D\n",
        "from keras import optimizers\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "#%Read the train & test Images and preprocessing\n",
        "train_images = []\n",
        "train_labels = [] \n",
        "for directory_path in glob.glob(\"/raid/Home/Users/aqayyum/pymultimodel/Classificationmodels/Datasetnew/*\"):\n",
        "    label = directory_path.split(\"\\\\\")[-1]\n",
        "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)       \n",
        "        img = cv2.resize(img, (224, 224))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        train_images.append(img)\n",
        "        train_labels.append(label)\n",
        "train_images = np.array(train_images)\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "label_to_id = {v:i for i,v in enumerate(np.unique(train_labels))}\n",
        "id_to_label = {v: k for k, v in label_to_id.items()}\n",
        "train_label_ids = np.array([label_to_id[x] for x in train_labels])\n",
        "#image_data = image_data.reshape(-1,10,24,24,1)\n",
        "train_images.shape, train_label_ids.shape, train_labels.shape\n",
        "X_train1, y_train1, N_CATEGORY =train_images,train_label_ids,len(label_to_id)\n",
        "\n",
        "\n",
        "ratio_train = 0.8\n",
        "ratio_val = 0.1\n",
        "ratio_test = 0.1\n",
        "\n",
        "# Produces test split.\n",
        "x_remaining, x_test, y_remaining, y_test = train_test_split(X_train1, y_train1, test_size=ratio_test)\n",
        "\n",
        "# Adjusts val ratio, w.r.t. remaining dataset.\n",
        "ratio_remaining = 1 - ratio_test\n",
        "ratio_val_adjusted = ratio_val / ratio_remaining\n",
        "\n",
        "# Produces train and val splits.\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_remaining, y_remaining, test_size=ratio_val_adjusted)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(x_val.shape)\n",
        "from keras.utils.np_utils import to_categorical\n",
        "y_train = keras.utils.to_categorical(y_train, 3)\n",
        "y_test = keras.utils.to_categorical(y_test, 3)\n",
        "y_val=keras.utils.to_categorical(y_val, 3)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "print(y_val.shape)\n",
        "\n",
        "X_train=x_train\n",
        "X_test=x_test\n",
        "X_val=x_val\n",
        "\n",
        "#%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pre_trained_modeld = DenseNet121(input_shape=(224, 224, 3), include_top=False, weights=\"imagenet\")\n",
        "\n",
        "for layer in pre_trained_modeld.layers:\n",
        "    print(layer.name)\n",
        "    layer.trainable = False\n",
        "    \n",
        "print(len(pre_trained_modeld.layers))\n",
        "\n",
        "#last_layer = pre_trained_modeld.get_layer('conv3_block12_concat')\n",
        "#last_layer = pre_trained_modeld.get_layer('conv4_block24_concat')\n",
        "#last_layer = pre_trained_modeld.get_layer('conv2_block6_concat')\n",
        "last_layer = pre_trained_modeld.get_layer('relu')\n",
        "print('last layer output shape:', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.GlobalMaxPooling2D()(last_output)\n",
        "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
        "x = layers.Dense(512, activation='relu',name='dens_densnet')(x)\n",
        "# Add a dropout rate of 0.7\n",
        "x = layers.Dropout(0.5)(x)\n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(3, activation='softmax')(x)\n",
        "# Configure and compile the model\n",
        "\n",
        "modeldensnet201 = Model(pre_trained_modeld.input, x)\n",
        "optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
        "modeldensnet201.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "modeldensnet201.summary()\n",
        "\n",
        "train_datagen = ImageDataGenerator(rotation_range=60, width_shift_range=0.2, height_shift_range=0.2,\n",
        "                                   shear_range=0.2, zoom_range=0.2, fill_mode='nearest')\n",
        "\n",
        "train_datagen.fit(X_train)\n",
        "\n",
        "val_datagen = ImageDataGenerator()\n",
        "val_datagen.fit(X_val)\n",
        "# Configure and compile the model\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 3\n",
        "history = modeldensnet201.fit_generator(train_datagen.flow(X_train,y_train, batch_size=batch_size),\n",
        "                              epochs = epochs, validation_data = val_datagen.flow(X_val, y_val),\n",
        "                              verbose = 1, steps_per_epoch=(X_train.shape[0] // batch_size), \n",
        "                              validation_steps=(X_val.shape[0] // batch_size))\n",
        "\n",
        "modeldensnet201.summary()\n",
        "for layer in pre_trained_modeld.layers:\n",
        "    layer.trainable = True\n",
        "    \n",
        "optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "modeldensnet201.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['acc'])\n",
        "\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, \n",
        "                                            min_lr=0.000001, cooldown=2)\n",
        "\n",
        "modeldensnet201.summary()\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 20\n",
        "history = modeldensnet201.fit_generator(train_datagen.flow(X_train,y_train, batch_size=batch_size),\n",
        "                              epochs = epochs, validation_data = val_datagen.flow(X_val, y_val),\n",
        "                              verbose = 1, steps_per_epoch=(X_train.shape[0] // batch_size),\n",
        "                              validation_steps=(X_val.shape[0] // batch_size),\n",
        "                              callbacks=[learning_rate_reduction])\n",
        "\n",
        "loss_val1, acc_val1 = modeldensnet201.evaluate(X_val, y_val, verbose=1)\n",
        "#print(\"Validation: accuracy = %f  ;  loss_v = %f\" % (acc_val1, loss_val1))\n",
        "\n",
        "#np.save('validaccudense',acc_val1)\n",
        "loss_test1, acc_test1 = modeldensnet201.evaluate(X_test, y_test, verbose=1)\n",
        "print(\"Test: accuracy = %f  ;  loss = %f\" % (acc_test1, loss_test1))\n",
        "#np.save('testaccudense',acc_test1)\n",
        "#\n",
        "#model.save(\"DenseNetFullWA.h5\")\n",
        "#\n",
        "###############################################33 Feature extraction from last layer#############################33\n",
        "####################################Feature extraction from last layer of model##########################\n",
        "layer_name = 'dens_densnet'\n",
        "FC_layer_modeldense = Model(inputs=modeldensnet201.input,\n",
        "                                 outputs=modeldensnet201.get_layer(layer_name).output)\n",
        "print('last layer output shape:', FC_layer_modeldense.output_shape)\n",
        "i=0\n",
        "featuresd=np.zeros(shape=(train_images.shape[0],512))\n",
        "#features=[]\n",
        "for directory_path in glob.glob(\"/raid/Home/Users/aqayyum/pymultimodel/Classificationmodels/Datasetnew/*\"):\n",
        "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)    \n",
        "        img = cv2.resize(img, (224, 224))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "        FC_output = FC_layer_modeldense.predict(img)\n",
        "        featuresd[i]=FC_output\n",
        "        i+=1\n",
        "#Save the features of the train images to use it in future.\n",
        "np.save('featuresdenseb5new', featuresd)\n",
        "#\n",
        "np.shape(featuresd)\n",
        "##Name the feature rows as f_0, f_1, f_2...\n",
        "feature_col=[]\n",
        "for i in range(512):\n",
        "    feature_col.append(\"f_\"+str(i))\n",
        "    i+=1\n",
        "train_featuresd=pd.DataFrame(data=featuresd,columns=feature_col)\n",
        "feature_col = np.array(feature_col)\n",
        "\n",
        "train_class = list(np.unique(train_label_ids))\n",
        "print('Training Features Shape:', train_featuresd.shape)\n",
        "print('Training Labels Shape:', train_label_ids.shape)\n",
        "\n",
        "X1=np.array(featuresd)\n",
        "y=np.array(train_label_ids)\n",
        "np.save('featuresdensepb6aug',X1)\n",
        "np.save('labelsdatapb6aug',train_label_ids)\n",
        "X_traind, X_testd, y_traind, y_testd = train_test_split(X1, y, test_size=0.2, stratify=y)\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "parameters = {\"n_neighbors\": [1, 5, 10, 30],\n",
        "              \"weights\": ['uniform', 'distance'],\n",
        "              \"metric\": ['minkowski','euclidean','manhattan'],\n",
        "              \"algorithm\": ['auto', 'ball_tree', 'kd_tree', 'brute']}\n",
        "kclf = KNeighborsClassifier()\n",
        "kgclf = GridSearchCV(kclf, param_grid=parameters)\n",
        "kgclf.fit(X_traind, y_traind)\n",
        "\n",
        "\n",
        "kclf = kgclf.best_estimator_\n",
        "kclf.fit(X_traind, y_traind)\n",
        "\n",
        "y_testKNN = kclf.predict(X_testd)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "#print_cmx(y_test1000.T[0], y_testKNN)\n",
        "print(classification_report(y_testd, y_testKNN))\n",
        "print(\"Accuracy: {0}\".format(accuracy_score(y_testd, y_testKNN)))\n",
        "modeldensnet201.save(\"DenseNetFullWagb6aug.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tm_EWVlA7zfh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pretrained inception model used for feature extraction and also used other machine learning classifies for classification\n",
        "import os\n",
        "from glob import glob\n",
        "#\n",
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import layers\n",
        "from keras import Model\n",
        "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os, shutil\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import glob\n",
        "import numpy as np\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from mpl_toolkits import mplot3d\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten, Reshape, Activation,SimpleRNN,GRU, LSTM\n",
        "from keras.layers.convolutional import Conv2D,Conv3D, Conv2DTranspose, Conv3DTranspose\n",
        "from keras.layers.convolutional import MaxPooling2D,MaxPooling3D, UpSampling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, SimpleRNN, LSTM, GRU, Dropout, Activation, Bidirectional, Conv2D, MaxPooling2D\n",
        "from keras import optimizers\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "import os\n",
        "from glob import glob\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import layers\n",
        "from keras import Model, Input\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.densenet import DenseNet201\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "\n",
        "#%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "from glob import glob\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import layers\n",
        "from keras import Model\n",
        "from keras.applications.densenet import DenseNet201\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os, shutil\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import glob\n",
        "import numpy as np\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from mpl_toolkits import mplot3d\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten, Reshape, Activation,SimpleRNN,GRU, LSTM\n",
        "from keras.layers.convolutional import Conv2D,Conv3D, Conv2DTranspose, Conv3DTranspose\n",
        "from keras.layers.convolutional import MaxPooling2D,MaxPooling3D, UpSampling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "#%Read the train & test Images and preprocessing\n",
        "train_images = []\n",
        "train_labels = [] \n",
        "for directory_path in glob.glob(\"/raid/Home/Users/aqayyum/pymultimodel/Classificationmodels/dataset_wAG/*\"):\n",
        "    label = directory_path.split(\"\\\\\")[-1]\n",
        "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)       \n",
        "        img = cv2.resize(img, (224, 224))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        train_images.append(img)\n",
        "        train_labels.append(label)\n",
        "train_images = np.array(train_images)\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "label_to_id = {v:i for i,v in enumerate(np.unique(train_labels))}\n",
        "id_to_label = {v: k for k, v in label_to_id.items()}\n",
        "train_label_ids = np.array([label_to_id[x] for x in train_labels])\n",
        "#image_data = image_data.reshape(-1,10,24,24,1)\n",
        "train_images.shape, train_label_ids.shape, train_labels.shape\n",
        "\n",
        "X_train1, y_train1, N_CATEGORY =train_images,train_label_ids,len(label_to_id)\n",
        "\n",
        "\n",
        "ratio_train = 0.8\n",
        "ratio_val = 0.1\n",
        "ratio_test = 0.1\n",
        "\n",
        "# Produces test split.\n",
        "x_remaining, x_test, y_remaining, y_test = train_test_split(X_train1, y_train1, test_size=ratio_test)\n",
        "\n",
        "# Adjusts val ratio, w.r.t. remaining dataset.\n",
        "ratio_remaining = 1 - ratio_test\n",
        "ratio_val_adjusted = ratio_val / ratio_remaining\n",
        "\n",
        "# Produces train and val splits.\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_remaining, y_remaining, test_size=ratio_val_adjusted)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(x_val.shape)\n",
        "from keras.utils.np_utils import to_categorical\n",
        "y_train = keras.utils.to_categorical(y_train, 3)\n",
        "y_test = keras.utils.to_categorical(y_test, 3)\n",
        "y_val=keras.utils.to_categorical(y_val, 3)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "print(y_val.shape)\n",
        "\n",
        "X_train=x_train\n",
        "X_test=x_test\n",
        "X_val=x_val\n",
        "\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#X_train, X_test, Y_train, Y_test = train_test_split(X_train1, y_train1, test_size=0.20)\n",
        "#X_train = X_train.astype('float32') / 255.\n",
        "#X_test = X_test.astype('float32') / 255.\n",
        "#from keras import utils as np_utils\n",
        "##Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "#from keras.utils.np_utils import to_categorical\n",
        "#y_train = keras.utils.to_categorical(Y_train, 3)\n",
        "#y_test = keras.utils.to_categorical(Y_test, 3)\n",
        "\n",
        "X_train = X_train.astype('float32') / 255.\n",
        "X_test = X_test.astype('float32') / 255.\n",
        "X_val = X_val.astype('float32') / 255.\n",
        "X_train=np.array(X_train)\n",
        "X_test=np.array(X_test)\n",
        "X_val=np.array(X_val)\n",
        "y_train=np.array(y_train)\n",
        "y_val=np.array(y_val)\n",
        "y_test=np.array(y_test)\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape=(224, 224, 3), include_top=False, weights=\"imagenet\")\n",
        "\n",
        "for layer in pre_trained_model.layers:\n",
        "    print(layer.name)\n",
        "    layer.trainable = False\n",
        "    \n",
        "print(len(pre_trained_model.layers))\n",
        "\n",
        "\n",
        "last_layer = pre_trained_model.get_layer('mixed9')\n",
        "print('last layer output shape:', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.GlobalMaxPooling2D()(last_output)\n",
        "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
        "x = layers.Dense(512, activation='relu',name='dens_icept')(x)\n",
        "# Add a dropout rate of 0.7\n",
        "x = layers.Dropout(0.5)(x)\n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(3, activation='softmax')(x)\n",
        "\n",
        "# Configure and compile the model\n",
        "\n",
        "modelinception = Model(pre_trained_model.input, x)\n",
        "optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
        "modelinception.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "modelinception.summary()\n",
        "train_datagen = ImageDataGenerator(rotation_range=60, width_shift_range=0.2, height_shift_range=0.2,\n",
        "                                   shear_range=0.2, zoom_range=0.2, fill_mode='nearest')\n",
        "print(X_train.shape)\n",
        "train_datagen.fit(X_train)\n",
        "print(X_val.shape)\n",
        "val_datagen = ImageDataGenerator()\n",
        "val_datagen.fit(X_val)\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 3\n",
        "history = modelinception.fit_generator(train_datagen.flow(X_train,y_train, batch_size=batch_size),\n",
        "                              epochs = epochs, validation_data = val_datagen.flow(X_val, y_val),\n",
        "                              verbose = 1, steps_per_epoch=(X_train.shape[0] // batch_size), \n",
        "                              validation_steps=(X_val.shape[0] // batch_size))\n",
        "\n",
        "\n",
        "for layer in pre_trained_model.layers:\n",
        "    layer.trainable = True\n",
        "    \n",
        "optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "modelinception.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['acc'])\n",
        "\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, \n",
        "                                            min_lr=0.000001, cooldown=2)\n",
        "\n",
        "\n",
        "modelinception.summary()\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 20\n",
        "history = modelinception.fit_generator(train_datagen.flow(X_train,y_train, batch_size=batch_size),\n",
        "                              epochs = epochs, validation_data = val_datagen.flow(X_val, y_val),\n",
        "                              verbose = 1, steps_per_epoch=(X_train.shape[0] // batch_size),\n",
        "                              validation_steps=(X_val.shape[0] // batch_size),\n",
        "                              callbacks=[learning_rate_reduction])\n",
        "\n",
        "\n",
        "loss_val, acc_val = modelinception.evaluate(X_val, y_val, verbose=1)\n",
        "print(\"Validation: accuracy = %f  ;  loss_v = %f\" % (acc_val, loss_val))\n",
        "#np.save('validaccuincept',acc_val)\n",
        "loss_test, acc_test = modelinception.evaluate(X_test, y_test, verbose=1)\n",
        "print(\"Test: accuracy = %f  ;  loss = %f\" % (acc_test, loss_test))\n",
        "#np.save('testaccuincept',acc_test)\n",
        "\n",
        "###################################Feature extraction from last layer of model##########################\n",
        "layer_name = 'dens_icept'\n",
        "FC_layer_modelincep = Model(inputs=modelinception.input,\n",
        "                                 outputs=modelinception.get_layer(layer_name).output)\n",
        "print('last layer output shape:', FC_layer_modelincep.output_shape)\n",
        "#%\n",
        "i=0\n",
        "features=np.zeros(shape=(train_images.shape[0],512))\n",
        "#features=[]\n",
        "for directory_path in glob.glob(\"/raid/Home/Users/aqayyum/pymultimodel/Classificationmodels/dataset_wAG/*\"):\n",
        "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)    \n",
        "        img = cv2.resize(img, (224, 224))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "        FC_output = FC_layer_modelincep.predict(img)\n",
        "        features[i]=FC_output\n",
        "        i+=1\n",
        "#Save the features of the train images to use it in future.\n",
        "#np.save('featuresinceptionawg', features)\n",
        "#\n",
        "np.shape(features)\n",
        "##Name the feature rows as f_0, f_1, f_2...\n",
        "#feature_col=[]\n",
        "#for i in range(512):\n",
        "#    feature_col.append(\"f_\"+str(i))\n",
        "#    i+=1\n",
        "#train_features=pd.DataFrame(data=features,columns=feature_col)\n",
        "#feature_col = np.array(feature_col)\n",
        "#\n",
        "#train_class = list(np.unique(train_label_ids))\n",
        "#print('Training Features Shape:', train_features.shape)\n",
        "#print('Training Labels Shape:', train_label_ids.shape)\n",
        "\n",
        "X=np.array(features)\n",
        "y=np.array(train_label_ids)\n",
        "np.save('featuresinceplast91',X)\n",
        "np.save('labelsdatlast91',train_label_ids)\n",
        "X_trainf, X_testf, y_trainf, y_testf = train_test_split(X, y, test_size=0.2, stratify=y)\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "parameters = {\"n_neighbors\": [1, 5, 10, 30],\n",
        "              \"weights\": ['uniform', 'distance'],\n",
        "              \"metric\": ['minkowski','euclidean','manhattan'],\n",
        "              \"algorithm\": ['auto', 'ball_tree', 'kd_tree', 'brute']}\n",
        "kclf = KNeighborsClassifier()\n",
        "kgclf = GridSearchCV(kclf, param_grid=parameters)\n",
        "kgclf.fit(X_trainf, y_trainf)\n",
        "\n",
        "\n",
        "kclf = kgclf.best_estimator_\n",
        "kclf.fit(X_trainf, y_trainf)\n",
        "\n",
        "y_testKNN = kclf.predict(X_testf)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "#print_cmx(y_test1000.T[0], y_testKNN)\n",
        "print(classification_report(y_testf, y_testKNN))\n",
        "print(\"Accuracy: {0}\".format(accuracy_score(y_testf, y_testKNN)))\n",
        "modelinception.save(\"InceptionV3last91.h5\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}