{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fine_TunepretrainedModel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGJ_wzcL7Jv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#base_dir = '/raid/Home/Users/aqayyum/pymultimodel/Classificationmodels/data2018/data/'\n",
        "base_dir = '/raid/Home/Users/aqayyum/pymultimodel/Classificationmodels/Datasetnew/' # path of your dataset mainfolder(subfolder number of classes)\n",
        "class_mode = 'categorical'\n",
        "metrics= ['categorical_accuracy', 'acc' ]\n",
        "dense_units=1024\n",
        "batch_size = 20\n",
        "epochs = 30\n",
        "\n",
        "#preprocessing\n",
        "validation_split = 0.2\n",
        "#color_channels = 3\n",
        "color_mode='rgb'\n",
        "#color_mode='grayscale'\n",
        "target_width = target_height = 299\n",
        "target_size = (target_height, target_width)\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    samplewise_center=True,\n",
        "    samplewise_std_normalization=True,\n",
        "    validation_split=0.2\n",
        ") # set validation split\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size, #default 256x256\n",
        "    class_mode=class_mode,\n",
        "    color_mode=color_mode, \n",
        "    subset='training') # set as training data\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    base_dir, # same directory as training data\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=class_mode, #Determines the type of label arrays that are returned:\"categorical\" will be 2D one-hot encoded labels,\n",
        "    color_mode=color_mode, \n",
        "    subset='validation') # set as validation data\n",
        "\n",
        "\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "# create the base pre-trained model\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
        "\n",
        "# add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(dense_units, activation='relu')(x)\n",
        "# and a logistic layer -- let's say we have 200 classes\n",
        "predictions = Dense(3, activation = 'softmax') (x)\n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# first: train only the top layers (which were randomly initialized)\n",
        "# i.e. freeze all convolutional InceptionV3 layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compile the model (should be done *after* setting layers to non-trainable)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=metrics)\n",
        "model.summary()\n",
        "# train the model on the new data for a few epochs\n",
        "history1=model.fit_generator(    \n",
        "    train_generator,\n",
        "    steps_per_epoch = train_generator.samples // batch_size,\n",
        "    validation_data = validation_generator, \n",
        "    validation_steps = validation_generator.samples // batch_size,\n",
        "    epochs = epochs)\n",
        "\n",
        "# at this point, the top layers are well trained and we can start fine-tuning\n",
        "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
        "# and train the remaining top layers.\n",
        "\n",
        "# let's visualize layer names and layer indices to see how many layers\n",
        "# we should freeze:\n",
        "for i, layer in enumerate(base_model.layers):\n",
        "   print(i, layer.name)\n",
        "\n",
        "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
        "# the first 249 layers and unfreeze the rest:\n",
        "for layer in model.layers[:249]:\n",
        "   layer.trainable = False\n",
        "for layer in model.layers[249:]:\n",
        "   layer.trainable = True\n",
        "\n",
        "# we need to recompile the model for these modifications to take effect\n",
        "# we use SGD with a low learning rate\n",
        "from keras.optimizers import SGD\n",
        "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=metrics)\n",
        "model.summary()\n",
        "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
        "# alongside the top Dense layers\n",
        "history2=model.fit_generator(    \n",
        "    train_generator,\n",
        "    steps_per_epoch = train_generator.samples // batch_size,\n",
        "    validation_data = validation_generator, \n",
        "    validation_steps = validation_generator.samples // batch_size,\n",
        "    epochs = epochs)\n",
        "\n",
        "#Confution Matrix and Classification Report\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "Y_pred = model.predict_generator(validation_generator, validation_generator.samples // batch_size+1)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(validation_generator.classes, y_pred))\n",
        "print('Classification Report')\n",
        "print(classification_report(validation_generator.classes, y_pred, target_names=labels))\n",
        "model.save('finetunedmodel.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}